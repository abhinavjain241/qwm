{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# San Diego Burrito Analytics: Data characterization\n",
    "\n",
    "Scott Cole\n",
    "\n",
    "1 July 2016\n",
    "\n",
    "This notebook applies nonlinear technqiues to analyze the contributions of burrito dimensions to the overall burrito rating.\n",
    "\n",
    "1. Create the ‘vitalness’ metric. For each dimension, identify the burritos that scored below average (defined as 2 or lower), then calculate the linear model’s predicted overall score and compare it to the actual overall score. For what dimensions is this distribution not symmetric around 0?\n",
    "    If this distribution trends greater than 0 (Overall_predict - Overall_actual), that means that the actual score is lower than the predicted score. This means that this metric is ‘vital’ and that it being bad will make the whole burrito bad\n",
    "    If vitalness < 0, then the metric being really bad actually doesn’t affect the overall burrito as much as it should.\n",
    "2. In opposite theme, make the ‘saving’ metric for all burritos in which the dimension was 4.5 or 5\n",
    "3. For those that are significantly different from 0, quantify the effect size. (e.g. a burrito with a 2 or lower rating for this metric: its overall rating will be disproportionately impacted by XX points).\n",
    "4. For the dimensions, how many are nonzero? If all of them are 0, then burritos are perfectly linear, which would be weird. If many of them are nonzero, then burritos are highly nonlinear. \n",
    "\n",
    "NOTE: A Neural network is not recommended because we should have 30x as many examples as weights (and for 3-layer neural network with 4 nodes in the first 2 layers and 1 in the last layer, that would be (16+4 = 20), so would need 600 burritos. One option would be to artificially create data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import pandasql\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import util\n",
    "df = util.load_burritos()\n",
    "N = df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vitalness metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vitalness(df, dim, rating_cutoff = 2,\n",
    "             metrics = ['Hunger','Tortilla','Temp','Meat','Fillings','Meatfilling',\n",
    "               'Uniformity','Salsa','Wrap']):\n",
    "    # Fit GLM to get predicted values\n",
    "    dffull = df[np.hstack((metrics,'overall'))].dropna()\n",
    "    X = sm.add_constant(dffull[metrics])\n",
    "    y = dffull['overall']\n",
    "    my_glm = sm.GLM(y,X)\n",
    "    res = my_glm.fit()\n",
    "    dffull['overallpred'] = res.fittedvalues\n",
    "    \n",
    "    # Make exception for Meat:filling in order to avoid pandasql error\n",
    "    if dim == 'Meat:filling':\n",
    "        dffull = dffull.rename(columns={'Meat:filling':'Meatfilling'})\n",
    "        dim = 'Meatfilling'\n",
    "\n",
    "    # Compare predicted and actual overall ratings for each metric below the rating cutoff\n",
    "    import pandasql\n",
    "    q = \"\"\"\n",
    "    SELECT\n",
    "    overall, overallpred\n",
    "    FROM\n",
    "    dffull\n",
    "    WHERE\n",
    "    \"\"\"\n",
    "    q = q + dim + ' <= ' + np.str(rating_cutoff)\n",
    "    df2 = pandasql.sqldf(q.lower(), locals())\n",
    "    return sp.stats.ttest_rel(df2.overall,df2.overallpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hunger\n",
      "Ttest_relResult(statistic=-3.365883957256508, pvalue=0.0780709343672088)\n",
      "Tortilla\n",
      "(nan, nan)\n",
      "Temp\n",
      "Ttest_relResult(statistic=-0.81348890082577441, pvalue=0.5652447600464281)\n",
      "Meat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Scott\\Anaconda2\\lib\\site-packages\\numpy\\core\\_methods.py:82: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_relResult(statistic=nan, pvalue=nan)\n",
      "Fillings\n",
      "(nan, nan)\n",
      "Meat:filling\n",
      "Ttest_relResult(statistic=-3.0834043861018237, pvalue=0.036809511325454659)\n",
      "Uniformity\n",
      "Ttest_relResult(statistic=-1.0261459655791099, pvalue=0.33896960697814343)\n",
      "Salsa\n",
      "Ttest_relResult(statistic=0.54602701695372891, pvalue=0.61407301073787002)\n",
      "Wrap\n",
      "Ttest_relResult(statistic=-0.81741849256402688, pvalue=0.43735446532724853)\n"
     ]
    }
   ],
   "source": [
    "vital_metrics = ['Hunger','Tortilla','Temp','Meat','Fillings','Meat:filling',\n",
    "               'Uniformity','Salsa','Wrap']\n",
    "for metric in vital_metrics:\n",
    "    print metric\n",
    "    if metric == 'Volume':\n",
    "        rating_cutoff = .7\n",
    "    else:\n",
    "        rating_cutoff = 1\n",
    "    print vitalness(df,metric,rating_cutoff=rating_cutoff, metrics=vital_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Savior metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def savior(df, dim, rating_cutoff = 2,\n",
    "             metrics = ['Hunger','Tortilla','Temp','Meat','Fillings','Meatfilling',\n",
    "               'Uniformity','Salsa','Wrap']):\n",
    "    \n",
    "    # Fit GLM to get predicted values\n",
    "    dffull = df[np.hstack((metrics,'overall'))].dropna()\n",
    "    X = sm.add_constant(dffull[metrics])\n",
    "    y = dffull['overall']\n",
    "    my_glm = sm.GLM(y,X)\n",
    "    res = my_glm.fit()\n",
    "    dffull['overallpred'] = res.fittedvalues\n",
    "    \n",
    "    # Make exception for Meat:filling in order to avoid pandasql error\n",
    "    if dim == 'Meat:filling':\n",
    "        dffull = dffull.rename(columns={'Meat:filling':'Meatfilling'})\n",
    "        dim = 'Meatfilling'\n",
    "\n",
    "    # Compare predicted and actual overall ratings for each metric below the rating cutoff\n",
    "    import pandasql\n",
    "    q = \"\"\"\n",
    "    SELECT\n",
    "    overall, overallpred\n",
    "    FROM\n",
    "    dffull\n",
    "    WHERE\n",
    "    \"\"\"\n",
    "    q = q + dim + ' >= ' + np.str(rating_cutoff)\n",
    "    df2 = pandasql.sqldf(q.lower(), locals())\n",
    "    print len(df2)\n",
    "    return sp.stats.ttest_rel(df2.overall,df2.overallpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hunger\n",
      "3\n",
      "Ttest_relResult(statistic=-0.67484451038709892, pvalue=0.56933333515759021)\n",
      "Tortilla\n",
      "1\n",
      "Ttest_relResult(statistic=nan, pvalue=nan)\n",
      "Temp\n",
      "21\n",
      "Ttest_relResult(statistic=-0.88123919839347509, pvalue=0.38865627728412522)\n",
      "Meat\n",
      "6\n",
      "Ttest_relResult(statistic=-2.3211799942541269, pvalue=0.067953603108261804)\n",
      "Fillings\n",
      "7\n",
      "Ttest_relResult(statistic=-1.0948905704812826, pvalue=0.31555790997898076)\n",
      "Meat:filling\n",
      "9\n",
      "Ttest_relResult(statistic=-1.7913421705001222, pvalue=0.11101175319719182)\n",
      "Uniformity\n",
      "14\n",
      "Ttest_relResult(statistic=-0.26954678056889914, pvalue=0.79174000333648464)\n",
      "Salsa\n",
      "3\n",
      "Ttest_relResult(statistic=-3.8348725849845149, pvalue=0.061765323303517049)\n",
      "Wrap\n",
      "38\n",
      "Ttest_relResult(statistic=-1.950837610088058, pvalue=0.058680682095782977)\n",
      "Volume\n",
      "14\n",
      "Ttest_relResult(statistic=-0.73069258289976113, pvalue=0.47793010155576998)\n"
     ]
    }
   ],
   "source": [
    "vital_metrics = ['Hunger','Tortilla','Temp','Meat','Fillings','Meat:filling',\n",
    "               'Uniformity','Salsa','Wrap']\n",
    "for metric in vital_metrics:\n",
    "    print metric\n",
    "    print savior(df,metric,rating_cutoff=5, metrics=vital_metrics)\n",
    "print 'Volume'\n",
    "vital_metrics = ['Hunger','Tortilla','Temp','Meat','Fillings','Meat:filling',\n",
    "               'Uniformity','Salsa','Wrap','Volume']\n",
    "print savior(df,'Volume',rating_cutoff=.9,metrics=vital_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
